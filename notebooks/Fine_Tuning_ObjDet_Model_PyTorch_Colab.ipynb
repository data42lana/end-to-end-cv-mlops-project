{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvH9aWTgf4Nd"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwEOY8c6bAan"
      },
      "source": [
        "### 1.1. Importing the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxjsI48Pq3bH"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import gc\n",
        "import random\n",
        "from pathlib import Path\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPxds8244o6N"
      },
      "outputs": [],
      "source": [
        "!pip install optuna &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyTUP6UyFc2D"
      },
      "outputs": [],
      "source": [
        "!pip install kaleido &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fih0i2Nfn8_A"
      },
      "outputs": [],
      "source": [
        "!pip install mlflow &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwtctTiMO2td"
      },
      "outputs": [],
      "source": [
        "# Image Augmentation\n",
        "import albumentations as A\n",
        "\n",
        "# Hyperparameter Optimization\n",
        "import optuna\n",
        "\n",
        "# Experiment Tracking\n",
        "import mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "encOC-cAsdqm"
      },
      "outputs": [],
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "from torch.utils.data import Dataset, Subset, DataLoader\n",
        "\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "from torchvision.ops import box_convert, box_iou\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "# Faster R-CNN (MobileNet)\n",
        "from torchvision.models.detection import fasterrcnn_mobilenet_v3_large_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q27WEDjeshXk"
      },
      "outputs": [],
      "source": [
        "print(A.__version__)\n",
        "print(optuna.__version__)\n",
        "print(mlflow.__version__)\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju1c6oTHJXlI"
      },
      "source": [
        "### 1.2. Setting general constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-VtbO6HKdwb"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8HFhEJCzJaz"
      },
      "outputs": [],
      "source": [
        "# Set partial reproducibility\n",
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWqiVvCPQx60"
      },
      "outputs": [],
      "source": [
        "PROJECT_PATH = Path('/content/drive/MyDrive/ML_Projects/How_many_Sparrows')\n",
        "DATA_PATH = PROJECT_PATH / 'data'\n",
        "IMAGE_PATH, BBOX_DATA_PATH = [DATA_PATH / 'raw' / data_path for data_path in ['images', 'bboxes/bounding_boxes.csv']]\n",
        "TRAIN_FILE_PATH, TEST_FILE_PATH = [DATA_PATH / 'prepared' / csv_file for csv_file in ['train.csv', 'test.csv']]\n",
        "SAVE_MODEL_PATH, MLRUN_PATH, HYPER_OPT_PATH = [PROJECT_PATH / savedir  for savedir in ['models', 'mlruns', 'hyper_opt']]\n",
        "\n",
        "for path in [SAVE_MODEL_PATH, MLRUN_PATH, HYPER_OPT_PATH]:\n",
        "    path.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMetjlQcCOiL"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'faster_rcnn_mob'\n",
        "NUM_CLASSES = 2 # 1 class (house sparrow) + background\n",
        "BATCH_SIZE = 16\n",
        "EVAL_IOU_THRESH = 0.4\n",
        "EVAL_BETA = 2\n",
        "EPOCHS = 15\n",
        "\n",
        "# Set the device to be used to run the model\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOx1zWcxau83"
      },
      "source": [
        "## 2. Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN6LpISEPx-s"
      },
      "source": [
        "### 2.1. For data manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iAxII2iHotX"
      },
      "outputs": [],
      "source": [
        "def get_image_transforms(box_format, save_aug_file_name=''):\n",
        "    \"\"\"Returns a Albumentation object and saves it to a JSON file \n",
        "    if save_aug_file_name is specified.\"\"\"\n",
        "    aug = A.Compose([\n",
        "                    A.LongestMaxSize(1333, always_apply=True),  \n",
        "                    A.SmallestMaxSize(800, always_apply=True),\n",
        "                    A.HorizontalFlip(p=0.6),\n",
        "                    A.VerticalFlip(p=0.4),\n",
        "                    A.ColorJitter(0.5, 0.5, 0.5, 0, p=0.7),\n",
        "                    A.RandomRain(p=0.5),\n",
        "                    A.OneOrOther(\n",
        "                        A.Blur(10, p=0.7),\n",
        "                        A.GaussianBlur((11, 21), p=0.3),\n",
        "                        p=0.6\n",
        "                        ),\n",
        "                    ], \n",
        "                    A.BboxParams(format=box_format, label_fields=['labels']),\n",
        "                    p=0.8)\n",
        "    \n",
        "    if save_aug_file_name:\n",
        "        config_path = PROJECT_PATH / 'configs'\n",
        "        config_path.mkdir(exist_ok=True)\n",
        "        A.save(aug, config_path / save_aug_file_name) \n",
        "\n",
        "    return aug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGjaEuUyakHA"
      },
      "outputs": [],
      "source": [
        "def stratified_group_train_test_split(data, stratification_basis, groups):\n",
        "    \"\"\"Stratified splits data into training and test sets,\n",
        "    taking into account groups, and returns the corresponding indices.\"\"\"\n",
        "    split = StratifiedGroupKFold(n_splits=2, shuffle=True, random_state=0)\n",
        "    train_ids, test_ids = next(split.split(X=data, y=stratification_basis, groups=groups))\n",
        "    return train_ids, test_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "if3MglFsMKlR"
      },
      "outputs": [],
      "source": [
        "def collate_batch(batch):\n",
        "    \"\"\"Collate batches in a Dataloader.\"\"\"\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e99Q7prhLHJG"
      },
      "outputs": [],
      "source": [
        "def draw_bboxes_on_image(img, bboxes, scores=None):\n",
        "    \"\"\"Draws an image with bounding boxes from Tensors.\"\"\"\n",
        "    if (img.dtype != torch.uint8):\n",
        "        img = T.functional.convert_image_dtype(img, dtype=torch.uint8)\n",
        "         \n",
        "    img_box = draw_bounding_boxes(img.detach(), boxes=bboxes, colors='orange', width=2)\n",
        "    img = to_pil_image(img_box.detach())\n",
        "    plt.figure(figsize=(8, 10))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    ax = plt.gca()\n",
        "    if scores is not None:\n",
        "        for bb, sc in zip(bboxes, scores):\n",
        "            x, y = bb.tolist()[:2]\n",
        "            text_sc = f\"{sc:0.2f}\"\n",
        "            ax.text(x, y, text_sc , fontsize=12, \n",
        "                    bbox=dict(facecolor='orange', alpha=0.5))\n",
        "            \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psnTWZmGTIyH"
      },
      "source": [
        "### 2.2. For a model training cycle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuREtVaBucDq"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(dataloader, model, optimizer, device=torch.device('cpu')):\n",
        "    \"\"\"Passes a training step in one epoch.\"\"\"\n",
        "    accum_dict_losses = {}\n",
        "    accum_model_loss = 0\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    # Set a model to the training mode\n",
        "    model.train()\n",
        "\n",
        "    for images, targets in dataloader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # Сompute a model batch losses\n",
        "        batch_dict_losses = model(images, targets)\n",
        "        batch_model_loss = sum([loss for loss in batch_dict_losses.values()])\n",
        "\n",
        "        # Accumulate statistics for computing the average losses per epoch\n",
        "        accum_dict_losses.update({\n",
        "            k: accum_dict_losses.get(k, 0) + v.item() for k, v in batch_dict_losses.items()\n",
        "            })\n",
        "        accum_model_loss += batch_model_loss.item()\n",
        "\n",
        "        # Optimize the model parameters\n",
        "        optimizer.zero_grad()\n",
        "        batch_model_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Free up memory\n",
        "        del images\n",
        "        del targets\n",
        "        gc.collect()\n",
        "\n",
        "        if str(device) == 'cuda':\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Compute the average losses\n",
        "    epoch_dict_losses = {k: v / num_batches for k, v in accum_dict_losses.items()}\n",
        "    epoch_model_loss = accum_model_loss / num_batches \n",
        "  \n",
        "    return {'epoch_dict_losses': epoch_dict_losses, \n",
        "            'epoch_loss': epoch_model_loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNHOIb06_1Wz"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def precision_recall_fbeta_scores(gts, preds, iou_thresh=0.5, beta=1):\n",
        "    \"\"\"Calculates the batch precision, recall, and f_beta scores based on IoU thresholds.\"\"\"\n",
        "    if (beta or iou_thresh) < 0:\n",
        "        raise ValueError(\"beta and iou_thresh should be >=0\")\n",
        "\n",
        "    total_gt_labels = []\n",
        "    total_correct_pred_labels = []\n",
        "\n",
        "    for gt, pred in zip(gts, preds):\n",
        "        total_gt_labels.append(gt['labels'])\n",
        "\n",
        "        if pred['boxes'].numel() != 0:\n",
        "            # Box IoU\n",
        "            gt_pred_box_iou = box_iou(gt['boxes'], pred['boxes']) \n",
        "            max_ious = torch.max(gt_pred_box_iou, dim=1)\n",
        "\n",
        "            # Mark box classification results as true and false positive base on a given IoU threshold\n",
        "            correct_pred_labels = torch.zeros_like(pred['labels'])\n",
        "            correct_pred_labels[max_ious.indices[max_ious.values >= iou_thresh]] = 1\n",
        "        else:\n",
        "            correct_pred_labels = torch.zeros_like(gt['labels'])\n",
        "\n",
        "        total_correct_pred_labels.append(correct_pred_labels)\n",
        "    \n",
        "    total_correct_pred_labels = torch.cat(total_correct_pred_labels)\n",
        "    total_gt_labels = torch.cat(total_gt_labels)\n",
        "\n",
        "    # Precision, recall, and f_beta scores'    \n",
        "    tp = sum(total_correct_pred_labels).item()\n",
        "    recall = tp / total_gt_labels.numel()\n",
        "    precision = tp / total_correct_pred_labels.numel()\n",
        "    denom = (beta**2 * precision) + recall\n",
        "    f_beta = ((1 + beta**2) * (precision * recall)) / denom if denom !=0 else 0\n",
        "    \n",
        "    return {'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f_beta': f_beta}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_0nny0tKfMF"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def eval_one_epoch(dataloader, model, iou_thresh=0.5, beta=1, device=torch.device('cpu')):\n",
        "    \"\"\"Passes a inference evaluation step in one epoch.\"\"\"\n",
        "    accum_model_scores = {}\n",
        "    results = []\n",
        "    num_batches = len(dataloader)\n",
        "    \n",
        "    # Set a model to the evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    for images, targets in dataloader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # Get prediction results\n",
        "        outputs = model(images)\n",
        "        results += outputs\n",
        "\n",
        "        # Сompute a model batch statistics\n",
        "        batch_model_scores = precision_recall_fbeta_scores(\n",
        "            targets, outputs, iou_thresh=iou_thresh, beta=beta)\n",
        "        \n",
        "        # Accumulate statistics for computing the average values per epoch\n",
        "        accum_model_scores.update({\n",
        "            k: accum_model_scores.get(k, 0) + v for k, v in batch_model_scores.items()\n",
        "            })\n",
        "\n",
        "        # Free up memory\n",
        "        del images\n",
        "        del outputs\n",
        "        gc.collect()\n",
        "\n",
        "        if str(device) == 'cuda':\n",
        "            torch.cuda.empty_cache()\n",
        "    \n",
        "    # Compute the average scores \n",
        "    epoch_model_scores = {k: v / num_batches for k, v in accum_model_scores.items()}\n",
        "\n",
        "    return {'epoch_scores': epoch_model_scores, \n",
        "            'results': results}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5KWbs4h5fVV"
      },
      "outputs": [],
      "source": [
        "def save_model_state(model_to_save, filename, ckpt_params_dict=None):\n",
        "    \"\"\"Saves a model state dictionary or a checkpoint.\"\"\"\n",
        "    filepath =  SAVE_MODEL_PATH / filename\n",
        "\n",
        "    if (ckpt_params_dict is not None) or isinstance(ckpt_params_dict, dict):\n",
        "        torch.save({'model_state_dict': model_to_save.state_dict(),\n",
        "                    **ckpt_params_dict}, filepath)\n",
        "    else:\n",
        "        torch.save(model_to_save.state_dict(), filepath)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p18wa2EOD6D_"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def predict(img, model, show_scores=False, device=torch.device('cpu')):\n",
        "    \"\"\"Draws an image with bounding boxes (and scores) and returns \n",
        "    a number of house sparrows on it.\n",
        "    \"\"\"\n",
        "    img = T.ToTensor()(img).to(device)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    preds = model([img])[0]\n",
        "    num_bboxes = len(preds['boxes'])\n",
        "\n",
        "    scores = None\n",
        "    if show_scores:\n",
        "        scores = preds['scores']\n",
        "        \n",
        "    print(str(num_bboxes) + \" house sparrow(s)\")\n",
        "    draw_bboxes_on_image(img, preds['boxes'], scores)\n",
        "    return num_bboxes    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CH1CWSQ2hHco"
      },
      "outputs": [],
      "source": [
        "def run_train(train_dataloader, val_dataloader, model, epochs, optimizer_name, optim_params, \n",
        "              lr_scheduler_name=None, lr_scheduler_params=None, device=torch.device('cpu'), \n",
        "              initial_f_beta_score=0, eval_iou_thresh=0.5, eval_beta=1, \n",
        "              model_name='best_model', save_best_ckpt=False, checkpoint=None, \n",
        "              log_metrics=False, register_best_log_model=False, \n",
        "              show_random_best_model_prediction=False):\n",
        "    \"\"\"Runs a new training and evaluation cycle of a model for a fixed number of epochs\n",
        "    or continue if checkpoint is passed, while saving the best model (or checkpoint).\n",
        "    \n",
        "    Parameters\n",
        "    -----------\n",
        "        train_dataloader (Dataloader) -- images, labels and boxes for a training step\n",
        "        val_dataloader (Dataloader) -- images, labels and boxes for an evaluation step\n",
        "        model (nn.Module) -- an object detection model\n",
        "        epochs (int) -- number of training epochs\n",
        "        optimizer_name (str) -- an optimizer name from torch.optim\n",
        "        optim_params (dict) -- relevant parameters for the optimizer\n",
        "        lr_scheduler_name (str) (optional) -- a learning rate scheduler name \n",
        "            from torch.optim.lr_scheduler (default None)\n",
        "        lr_scheduler_params (dict) (optional) -- relevant parameters for \n",
        "            the learning rate scheduler (default None)\n",
        "        device (torch.device) -- a type of device used: torch.device('cpu' or 'cuda') \n",
        "            (default torch.device('cpu'))\n",
        "        initial_f_beta_score (float) -- an initial f beta score to find the best model (default 0.0)\n",
        "        eval_iou_thresh (float) -- an iou threshold to determine correct predict boxes (default 0.5)\n",
        "        eval_beta (int) -- a beta value for f beta score (default 1)\n",
        "        model_name (str) -- a part of filename to save (default 'best_model')\n",
        "        save_best_ckpt (bool) -- whether to save the best model (default) \n",
        "            or its checkpoint (default False)\n",
        "        checkpoint (dict) (optional) -- a checkpoint to continue training (default None)\n",
        "        log_metrics (bool) -- whether to log metrics into MLflow (default False)\n",
        "        register_best_log_model (bool) -- whether to log and register the best model \n",
        "            into MLflow (default False)\n",
        "        show_random_best_model_prediction (bool) -- whether to show a random prediction \n",
        "            of the best model (default False).\n",
        "\n",
        "    Returns\n",
        "    -----------\n",
        "        a dictionary of training and evaluation results.\n",
        "    \"\"\" \n",
        "    print(\"Device: \", device)    \n",
        "    start_epoch = 0\n",
        "    best_epoch_f_beta_score = initial_f_beta_score\n",
        "    lr_scheduler = None\n",
        "\n",
        "    model_params = [p for p in model.parameters() if p.requires_grad]\n",
        "    # Construct an optimizer\n",
        "    optimizer = getattr(torch.optim, optimizer_name)(model_params, **optim_params)\n",
        "\n",
        "    if lr_scheduler_name is not None:\n",
        "        if lr_scheduler_params is None:\n",
        "            lr_scheduler_params = {}\n",
        "        # Construct a learning rate scheduler\n",
        "        lr_scheduler = getattr(torch.optim.lr_scheduler, lr_scheduler_name)(optimizer, \n",
        "                                                                            **lr_scheduler_params)\n",
        "    \n",
        "    if checkpoint is not None:\n",
        "        # Get state parameters from the checkpoint\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        best_epoch_f_beta_score = checkpoint['f_beta_score']\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        current_epoch = start_epoch + epoch\n",
        "        print(f\"EPOCH [{current_epoch}/{start_epoch + epochs}]: \")\n",
        "\n",
        "        # Training step\n",
        "        print(\"TRAIN:\")\n",
        "        train_res = train_one_epoch(train_dataloader, model, optimizer, device)\n",
        "        print(\"  epoch loss: {0}:\\n    {1}\".format(train_res['epoch_loss'], \n",
        "                                                   train_res['epoch_dict_losses']))\n",
        "\n",
        "        if lr_scheduler is not None:\n",
        "            lr_scheduler.step()        \n",
        "        \n",
        "        # Evaluation step\n",
        "        print(\"EVAL:\")\n",
        "        eval_res = eval_one_epoch(val_dataloader, model, eval_iou_thresh, eval_beta, device)\n",
        "        print(\"\\n  epoch scores: {}\".format(eval_res['epoch_scores'])) \n",
        "        \n",
        "        # Save a model with the maximum f_beta score\n",
        "        if best_epoch_f_beta_score < eval_res['epoch_scores']['f_beta']:\n",
        "            best_epoch_f_beta_score = eval_res['epoch_scores']['f_beta']\n",
        "            ckpt_dict = None\n",
        "            filename = model_name + f'_best_f_beta_{eval_beta}_weights'\n",
        "            \n",
        "            if register_best_log_model:\n",
        "                try:\n",
        "                    # Log and register the best model into MLflow\n",
        "                    mlflow.pytorch.log_model(model, filename, registered_model_name='best_' + MODEL_NAME, \n",
        "                                             await_registration_for=30, \n",
        "                                             pip_requirements=[f'torch={torch.__version__}', \n",
        "                                                               f'torchvision={torchvision.__version__}'])\n",
        "                except NameError: \n",
        "                    print(\"Warning: The Model cannot be registered! -- MLflow module is not imported.\")\n",
        "\n",
        "            if save_best_ckpt:\n",
        "                ckpt_dict = {'epoch': current_epoch,            \n",
        "                                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                                'f_beta_score': best_epoch_f_beta_score}\n",
        "                filename += '_ckpt'\n",
        "\n",
        "            save_model_state(model, filename + '.pt', ckpt_dict)\n",
        "            print(f\"Model is saved. --- The best f_beta score: {best_epoch_f_beta_score}\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                if show_random_best_model_prediction:\n",
        "                    sample_imgs, _ = next(iter(val_dataloader))\n",
        "                    sample_idx = random.randint(0, len(sample_imgs)-1)\n",
        "                    preds = eval_res['results'][sample_idx]\n",
        "                    draw_bboxes_on_image(sample_imgs[sample_idx], preds['boxes'], preds['scores'])\n",
        "                    del sample_imgs\n",
        "                    del preds\n",
        "                                \n",
        "        if log_metrics: \n",
        "            try:   \n",
        "                # Log losses and scores into MLflow       \n",
        "                mlflow.log_metric('train_epoch_loss', train_res['epoch_loss'], step=current_epoch)\n",
        "                mlflow.log_metrics(train_res['epoch_dict_losses'], step=current_epoch)\n",
        "                mlflow.log_metrics(eval_res['epoch_scores'], step=current_epoch)\n",
        "                print(\"Metrics are logged.\")\n",
        "            except NameError: \n",
        "                print(\"Warning: Metrics cannot be logged! -- MLflow module is not imported.\")\n",
        "\n",
        "        # Free up memory\n",
        "        gc.collect()\n",
        "        if str(device) == 'cuda':\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    print(\"DONE!\")\n",
        "    return {'train_res': train_res,\n",
        "            'eval_res': eval_res}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jpt3EoIUNvW"
      },
      "source": [
        "## 3. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut1-3E3yT_JZ"
      },
      "outputs": [],
      "source": [
        "class ImageBBoxDataset(Dataset):\n",
        "    \"\"\"A Dataset from csv to detect objects in images.\"\"\"\n",
        "    def __init__(self, csv_file_path, img_dir_path, bbox_path, \n",
        "                 img_transforms=None, bbox_transform=None):\n",
        "        self.img_dir_path = img_dir_path\n",
        "        self.img_df = pd.read_csv(csv_file_path)\n",
        "        self.bbox_df = pd.read_csv(bbox_path)\n",
        "        self.img_transforms = img_transforms\n",
        "        self.bbox_transform = bbox_transform # (bbox_transform_fn, *bbox_transform_args) \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.img_df.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.img_df.iloc[idx, 0]\n",
        "        img_path = self.img_dir_path / img_name\n",
        "        image = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)\n",
        "        bboxes = self.bbox_df.loc[(self.bbox_df.image_name == img_name), \n",
        "                                 ['bbox_x', 'bbox_y', 'bbox_width', 'bbox_height']].values\n",
        "        labels = torch.ones((bboxes.shape[0],), dtype=torch.int64) \n",
        "\n",
        "        if self.img_transforms:\n",
        "            aug = self.img_transforms(image=image, bboxes=bboxes, labels=labels)\n",
        "            image = aug['image']\n",
        "            bboxes = aug['bboxes']\n",
        "                 \n",
        "        image = T.ToTensor()(image)\n",
        "        bboxes = torch.as_tensor(bboxes, dtype=torch.float)\n",
        "\n",
        "        if self.bbox_transform:\n",
        "            bboxes = self.bbox_transform[0](bboxes, *self.bbox_transform[1:])\n",
        "             \n",
        "        target = {'boxes': bboxes,\n",
        "                  'labels': labels}\n",
        "\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPslGRjDptOl"
      },
      "outputs": [],
      "source": [
        "def get_train_val_test_dataloaders(batch_size, transform_train_img=False, save_img_transform_file=None):\n",
        "    \"\"\"Returns training, validation, and test dataloaders with box transformation from 'xywh' to 'xyxy' format.\"\"\"\n",
        "    dataset_params = {\n",
        "        'img_dir_path': IMAGE_PATH,\n",
        "        'bbox_path': BBOX_DATA_PATH, \n",
        "        'bbox_transform': (box_convert, 'xywh', 'xyxy')\n",
        "    }\n",
        "    img_transforms = None\n",
        "    box_format_before_transform = 'coco'\n",
        "\n",
        "    if transform_train_img:\n",
        "        img_transforms = get_image_transforms(box_format_before_transform, save_img_transform_file)\n",
        "\n",
        "    train_dataset = ImageBBoxDataset(TRAIN_FILE_PATH, img_transforms=img_transforms, **dataset_params)\n",
        "    val_dataset = ImageBBoxDataset(TRAIN_FILE_PATH, **dataset_params) \n",
        "    test_dataset = ImageBBoxDataset(TEST_FILE_PATH, **dataset_params)\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    train_ids, val_ids = stratified_group_train_test_split(train_dataset.img_df['Name'], \n",
        "                                                           train_dataset.img_df['Number_HSparrows'], \n",
        "                                                           train_dataset.img_df['Author'])    \n",
        "    dl_params = {'batch_size': batch_size,\n",
        "                 'collate_fn': collate_batch} \n",
        "    train_dataloader = DataLoader(Subset(train_dataset, train_ids), shuffle=True, **dl_params)\n",
        "    val_dataloader = DataLoader(Subset(val_dataset, val_ids), **dl_params)\n",
        "    test_dataloader = DataLoader(test_dataset, **dl_params)\n",
        "\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAaafF-UbaCe"
      },
      "outputs": [],
      "source": [
        "train_dl, val_dl, test_dl = get_train_val_test_dataloaders(BATCH_SIZE, transform_train_img=True, \n",
        "                                                           save_img_transform_file='image_augmentation_params')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdlO14XcQyz5"
      },
      "outputs": [],
      "source": [
        "# Draw a sample image with bounding boxes on it\n",
        "sample_imgs, sample_targets = next(iter(train_dl))\n",
        "sample_idx = random.randint(0, len(sample_imgs)-1)\n",
        "draw_bboxes_on_image(sample_imgs[sample_idx], bboxes=sample_targets[sample_idx]['boxes'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvbzVAT4DZDC"
      },
      "source": [
        "## 4. Object Detection Model Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JViQy7hMEmrD"
      },
      "source": [
        "### 4.1. Model loading and preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2Qmi6Os8J3K"
      },
      "outputs": [],
      "source": [
        "def faster_rcnn_mob_model_for_n_classes(num_classes, print_head=False, **load_model_params):\n",
        "    \"\"\"Loads a pre-trained Faster R-CNN (MobileNet Large) model \n",
        "    and modifies it to classify N classes (true classes + background).\"\"\"\n",
        "    # Load a Faster R-CNN model pre-trained on COCO\n",
        "    faster_rcnn_mob = fasterrcnn_mobilenet_v3_large_fpn(weights='COCO_V1', **load_model_params)\n",
        "\n",
        "    if print_head:\n",
        "        print(\"The Model's Head - Before: \\n\", faster_rcnn_mob.roi_heads.box_predictor)\n",
        "\n",
        "    # Get number of input features for the predictor\n",
        "    in_features_mob = faster_rcnn_mob.roi_heads.box_predictor.cls_score.in_features\n",
        "    # Replace the pre-trained head with a new one\n",
        "    faster_rcnn_mob.roi_heads.box_predictor = FastRCNNPredictor(in_features_mob, num_classes=num_classes)\n",
        "\n",
        "    if print_head:\n",
        "        print(\"The Model's Head - After: \\n\", faster_rcnn_mob.roi_heads.box_predictor)\n",
        "\n",
        "    return faster_rcnn_mob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "233uFt9TVInL"
      },
      "outputs": [],
      "source": [
        "# Set model parameters\n",
        "model_params = dict(\n",
        "    trainable_backbone_layers=1, # during training    \n",
        "    rpn_score_thresh=0.4, # during inference \n",
        "    box_score_thresh=0.5, # during inference\n",
        "    box_nms_thresh=0.4, # during inference\n",
        "    box_detections_per_img=120,\n",
        "    box_positive_fraction=0.4 # during training\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI5RFSxZ-jia"
      },
      "outputs": [],
      "source": [
        "# Get a modified model\n",
        "faster_rcnn_mob_model = faster_rcnn_mob_model_for_n_classes(NUM_CLASSES, print_head=True, **model_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuD6Zx0z-oUs"
      },
      "source": [
        "### 4.2. Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAMh0hCXIPY5"
      },
      "outputs": [],
      "source": [
        "# Log parameters and metrics during hyperparameter optimization into MLflow\n",
        "mlflow.set_tracking_uri(MLRUN_PATH.as_uri())\n",
        "hyp_opt_exp = mlflow.get_experiment_by_name('Hyperparameter_Optimization')\n",
        "general_run_tags = {'model_name': MODEL_NAME, 'tools.training': 'PyTorch'}\n",
        "\n",
        "if hyp_opt_exp is not None:\n",
        "    hyp_opt_exp_id = hyp_opt_exp.experiment_id\n",
        "else:\n",
        "    hyp_opt_exp_id = mlflow.create_experiment('Hyperparameter_Optimization')\n",
        "\n",
        "mlc = optuna.integration.mlflow.MLflowCallback(\n",
        "    tracking_uri=mlflow.get_tracking_uri(), \n",
        "    metric_name='f_beta', create_experiment=False, \n",
        "    mlflow_kwargs={\n",
        "        'experiment_id': hyp_opt_exp_id, \n",
        "        'run_name': 'HO_TPE_Median', \n",
        "        'tags': {'sampler': 'TPESampler', \n",
        "                 'pruner': 'MedianPruner',\n",
        "                 'tools.hyper_opt': 'Optuna',\n",
        "                 **general_run_tags}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBIcZTNo6mjU"
      },
      "outputs": [],
      "source": [
        "@mlc.track_in_mlflow()\n",
        "def objective(trial):\n",
        "    \"\"\"The function to be optimized.\"\"\"\n",
        "    # Get dataloaders\n",
        "    train_dl, val_dl, _ = get_train_val_test_dataloaders(BATCH_SIZE)        \n",
        "  \n",
        "    # Load a model\n",
        "    model_params = dict(\n",
        "        trainable_backbone_layers=1, # during training\n",
        "        rpn_score_thresh=0.4, # during inference\n",
        "        box_score_thresh=0.5, # during inference\n",
        "        box_nms_thresh=0.4, # during inference\n",
        "        box_detections_per_img=120, # during inference\n",
        "        box_positive_fraction=0.4 # during training\n",
        "    )   \n",
        "    frcnn_mob_model = faster_rcnn_mob_model_for_n_classes(NUM_CLASSES, **model_params)\n",
        "    frcnn_mob_model.to(DEVICE)  \n",
        "    \n",
        "    # Construct a training optimizer and lr_scheduler\n",
        "    lr_scheduler = None\n",
        "    lr_scheduler_params = {} \n",
        "\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', ['SGD', 'Adam'])\n",
        "    optim_params = {\n",
        "        'lr': trial.suggest_float('lr', 1e-5, 1e-2, log=True),\n",
        "        'weight_decay': trial.suggest_float('weight_decay', 0.0, 0.001, step=0.0001),\n",
        "    }    \n",
        "\n",
        "    if optimizer_name == 'SGD':\n",
        "        optim_params['momentum'] = trial.suggest_float('momentum', 0.0, 0.9, step=0.3)\n",
        "\n",
        "    lr_scheduler_name = trial.suggest_categorical('lr_scheduler', [None, 'StepLR', 'LinearLR'])\n",
        "\n",
        "    if lr_scheduler_name == 'StepLR':\n",
        "        lr_scheduler_params['step_size'] = trial.suggest_int('step_size', 1, 3)\n",
        "        lr_scheduler_params['gamma'] = trial.suggest_float('gamma', 0.1, 0.2, log=True)\n",
        "\n",
        "    train_model_params = [p for p in frcnn_mob_model.parameters() if p.requires_grad]\n",
        "    optimizer = getattr(torch.optim, optimizer_name)(train_model_params, **optim_params)\n",
        "\n",
        "    if lr_scheduler_name is not None:\n",
        "        lr_scheduler = getattr(torch.optim.lr_scheduler, lr_scheduler_name)(optimizer, **lr_scheduler_params)\n",
        "    \n",
        "    # Log parameters into MLflow\n",
        "    mlflow.log_params({'device': DEVICE,\n",
        "                       'num_classes': NUM_CLASSES,\n",
        "                       'batch_size': BATCH_SIZE})                     \n",
        "    mlflow.log_params({'eval_iou_thresh': EVAL_IOU_THRESH,\n",
        "                       'eval_beta': EVAL_BETA,\n",
        "                       **model_params})\n",
        "    mlflow.log_params({'optimizer': optimizer_name,\n",
        "                       'lr_scheduler': lr_scheduler_name,\n",
        "                       **lr_scheduler_params,\n",
        "                       **optim_params})\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(1, 11):\n",
        "        train_res = train_one_epoch(train_dl, frcnn_mob_model, optimizer, DEVICE)\n",
        "\n",
        "        if lr_scheduler is not None:\n",
        "            lr_scheduler.step()        \n",
        "\n",
        "        eval_res = eval_one_epoch(val_dl, frcnn_mob_model, EVAL_IOU_THRESH , EVAL_BETA, DEVICE)\n",
        "        f_beta_score = eval_res['epoch_scores']['f_beta']\n",
        "        trial.report(f_beta_score, epoch)\n",
        "        \n",
        "        # Log metrics into MLflow\n",
        "        mlflow.log_metric('train_epoch_loss', train_res['epoch_loss'], step=epoch)\n",
        "        mlflow.log_metrics(train_res['epoch_dict_losses'], step=epoch)\n",
        "        mlflow.log_metrics(eval_res['epoch_scores'], step=epoch)\n",
        "\n",
        "        # Handle pruning\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    return f_beta_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHU-EkMtqKPE"
      },
      "outputs": [],
      "source": [
        "# Set study parameters\n",
        "study_callbacks=[mlc]\n",
        "\n",
        "if str(DEVICE) == 'cuda':\n",
        "    study_callbacks.append(lambda study, trial: torch.cuda.empty_cache())\n",
        "\n",
        "study_storage = optuna.storages.RDBStorage(url='sqlite:///{}'.format(HYPER_OPT_PATH / 'hyper_opt_studies.db'))\n",
        "study_name='faster_rcnn_mob_hyper_opt_study'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mobyNa7cibHp"
      },
      "outputs": [],
      "source": [
        "# Run a optimization session\n",
        "study = optuna.create_study(direction='maximize', \n",
        "                            pruner=optuna.pruners.MedianPruner(n_warmup_steps=3),\n",
        "                            storage=study_storage, study_name=study_name, \n",
        "                            load_if_exists=True)\n",
        "\n",
        "study.optimize(objective, n_trials=100, timeout=2400, callbacks=study_callbacks,\n",
        "               gc_after_trial=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYzQ2qxesP8G"
      },
      "outputs": [],
      "source": [
        "# Show the best parameters and metric value\n",
        "print(f\"The best trial:\\n  f_beta: {study.best_value}\\n  params: \")\n",
        "for k, v in study.best_params.items():\n",
        "    print(f\"    {k}: {v}\")\n",
        "print(\"  duration: {}s\".format(study.best_trial.duration))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzCyw1jqQK9n"
      },
      "outputs": [],
      "source": [
        "# View N trials\n",
        "trials_df2 = study.trials_dataframe(attrs=('number', 'value', 'duration', 'params', 'state'))\n",
        "trials_df2.head(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqyq3m3trILx"
      },
      "outputs": [],
      "source": [
        "# Save study result plots\n",
        "plots = [optuna.visualization.plot_optimization_history,\n",
        "         optuna.visualization.plot_intermediate_values,\n",
        "         optuna.visualization.plot_parallel_coordinate,\n",
        "         optuna.visualization.plot_contour,\n",
        "         optuna.visualization.plot_slice,\n",
        "         optuna.visualization.plot_param_importances,\n",
        "         optuna.visualization.plot_edf]\n",
        "\n",
        "for plot in plots:\n",
        "    fig = plot(study)\n",
        "    fname = plot.__name__[5:]\n",
        "    save_path = HYPER_OPT_PATH / 'plots' / study_name\n",
        "    save_path.mkdir(parents=True, exist_ok=True)\n",
        "    fig.write_image(save_path / f'{fname}.jpeg') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLN1XRK8jlGK"
      },
      "source": [
        "### 4.3. Fine-tuning the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mw5197-QAmw"
      },
      "outputs": [],
      "source": [
        "# Set the best parameters found during optimization\n",
        "loaded_study = optuna.load_study(study_name=study_name, storage=study_storage)\n",
        "best_params = loaded_study.best_params\n",
        "print(\"The best training parameters: \\n\", best_params)\n",
        "\n",
        "optimized_train_params = {\n",
        "    'optimizer_name': best_params['optimizer'],\n",
        "    'lr_scheduler_name': best_params['lr_scheduler']\n",
        "    }\n",
        "\n",
        "for opt, params in zip(('optim_params', 'lr_scheduler_params'), \n",
        "                      (['lr', 'momentum', 'weight_decay'], ['step_size', 'gamma'])):\n",
        "    opt_dict = {p: best_params[p] for p in params if p in best_params}\n",
        "    optimized_train_params[opt] = opt_dict\n",
        "\n",
        "add_train_params = {'epochs': EPOCHS, \n",
        "                    'eval_iou_thresh': EVAL_IOU_THRESH, \n",
        "                    'eval_beta': EVAL_BETA,\n",
        "                    'device': DEVICE}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQjBpudMbFqu"
      },
      "outputs": [],
      "source": [
        "# Train the model (fine-tuning) with optimized parameters and log metrics \n",
        "# and the parameters into MLflow\n",
        "ftm_exp = mlflow.get_experiment_by_name('Fine-Tuning_Model')\n",
        "mlflow.set_registry_uri('sqlite:///{}'.format(MLRUN_PATH / 'model_registry.db'))\n",
        "\n",
        "if ftm_exp is not None:\n",
        "    ftm_exp_id = ftm_exp.experiment_id\n",
        "else:  \n",
        "    ftm_exp_id = mlflow.create_experiment('Fine-Tuning_Model')\n",
        "\n",
        "with mlflow.start_run(run_name='fine-tuning_with_optimized_parameters', \n",
        "    experiment_id=ftm_exp_id) as mlft_run:\n",
        "    mlflow.set_tags({'training_process': 'fine_tuning',\n",
        "                    **general_run_tags})\n",
        "\n",
        "    # Run model training cycles\n",
        "    faster_rcnn_mob_res = run_train(train_dl, val_dl, faster_rcnn_mob_model, \n",
        "                                    initial_f_beta_score=0.5, log_metrics=True, \n",
        "                                    save_best_ckpt=True, model_name=MODEL_NAME,\n",
        "                                    show_random_best_model_prediction=True,\n",
        "                                    register_best_log_model=True,\n",
        "                                    **optimized_train_params, **add_train_params)\n",
        "\n",
        "    # Log the parameters into MLflow\n",
        "    mlflow.log_params(model_params)\n",
        "    mlflow.log_params({'batch_size': BATCH_SIZE,\n",
        "                       'num_classes': NUM_CLASSES})\n",
        "    mlflow.log_params(add_train_params)\n",
        "    mlflow.log_params(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBy572ZPtblS"
      },
      "source": [
        "### 4.4. Loading the best model and evaluating it on test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l-ggJ05Yubr"
      },
      "outputs": [],
      "source": [
        "# Load the best model from the MLflow registry\n",
        "client = mlflow.MlflowClient()\n",
        "reg_model_name = 'best_' + MODEL_NAME\n",
        "model_registry_info = client.get_latest_versions(reg_model_name)\n",
        "model_latest_version = max([m.version for m in model_registry_info])\n",
        "\n",
        "model_uri = 'models:/{}/{}'.format(reg_model_name, model_latest_version)\n",
        "best_faster_rcnn_mob_model = mlflow.pytorch.load_model(model_uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YKF2TGHI8Ea"
      },
      "outputs": [],
      "source": [
        "# Evaluate the best model on test data\n",
        "test_res = eval_one_epoch(test_dl, best_faster_rcnn_mob_model, EVAL_IOU_THRESH, EVAL_BETA, DEVICE)\n",
        "print(test_res['epoch_scores'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1J0blc60mnIL"
      },
      "outputs": [],
      "source": [
        "# Show a random test image sample with predict boxes and scores\n",
        "test_imgs_df = pd.read_csv(TEST_FILE_PATH, usecols=['Name'])\n",
        "test_sample_idx = random.randint(0, test_imgs_df.size-1)\n",
        "test_sample_img = cv2.cvtColor(cv2.imread(str(IMAGE_PATH / test_imgs_df.iloc[test_sample_idx].Name)), \n",
        "                               cv2.COLOR_BGR2RGB)\n",
        "_ = predict(test_sample_img, best_faster_rcnn_mob_model, show_scores=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXKeTXGiKzdN"
      },
      "outputs": [],
      "source": [
        "# # Uncomment to update model version stages\n",
        "# for m in model_registry_info:    \n",
        "#     if m.version == model_latest_version:\n",
        "#         if m.current_stage == 'Production':\n",
        "#             continue\n",
        "#         else:\n",
        "#             m = client.transition_model_version_stage(\n",
        "#                     name=reg_model_name,\n",
        "#                     version=m.version,\n",
        "#                     stage='Production')\n",
        "#     else:\n",
        "#         if m.current_stage == 'Production':\n",
        "#             m = client.transition_model_version_stage(\n",
        "#                     name=reg_model_name,\n",
        "#                     version=m.version,\n",
        "#                     stage='Archived')\n",
        "            \n",
        "# # View updated model version stages\n",
        "# for m in client.get_latest_versions(reg_model_name):\n",
        "#     print(f'{m.name}: version: {m.version}, current stage: {m.current_stage}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DvH9aWTgf4Nd",
        "WwEOY8c6bAan",
        "ju1c6oTHJXlI",
        "cOx1zWcxau83",
        "aN6LpISEPx-s",
        "psnTWZmGTIyH",
        "_Jpt3EoIUNvW",
        "JViQy7hMEmrD",
        "YuD6Zx0z-oUs",
        "nLN1XRK8jlGK",
        "UBy572ZPtblS"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b2ab1ef63cc1d0e1338c1d8132759d9e4f4760c8169058413a208056ba3b8064"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
